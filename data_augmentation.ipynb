{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "### Nov 4 2021\n",
    "### Mersad Masoud\n",
    "#### *Zlab Project*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Code using Augmentor Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Augmentor\n",
      "  Using cached Augmentor-0.2.9-py2.py3-none-any.whl (38 kB)\n",
      "Collecting future>=0.16.0\n",
      "  Using cached future-0.18.2.tar.gz (829 kB)\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\users\\msi\\miniconda3\\lib\\site-packages (from Augmentor) (1.19.5)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in c:\\users\\msi\\miniconda3\\lib\\site-packages (from Augmentor) (8.3.2)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in c:\\users\\msi\\miniconda3\\lib\\site-packages (from Augmentor) (4.61.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi\\miniconda3\\lib\\site-packages (from tqdm>=4.9.0->Augmentor) (0.4.4)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491059 sha256=49a8deb1ca0b6c811b0ea966d7050363693224f89d9152dc774e949d08371918\n",
      "  Stored in directory: c:\\users\\msi\\appdata\\local\\pip\\cache\\wheels\\2f\\a0\\d3\\4030d9f80e6b3be787f19fc911b8e7aa462986a40ab1e4bb94\n",
      "Successfully built future\n",
      "Installing collected packages: future, Augmentor\n",
      "Successfully installed Augmentor-0.2.9 future-0.18.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 1 image(s) found.\n",
      "Output directory set to ./output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing <PIL.Image.Image image mode=RGB size=1920x1280 at 0x140E929A670>: 100%|██████████| 5/5 [00:01<00:00,  4.08 Samples/s]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary library\n",
    "import Augmentor\n",
    "# Passing the path of the image directory\n",
    "p = Augmentor.Pipeline(\"./\")\n",
    "  \n",
    "# Defining augmentation parameters and generating 5 samples\n",
    "p.flip_left_right(0.5)\n",
    "p.black_and_white(0.1)\n",
    "p.rotate(0.3, 10, 10)\n",
    "p.skew(0.4, 0.5)\n",
    "p.zoom(probability = 0.2, min_factor = 1.1, max_factor = 1.5)\n",
    "p.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# نتایج تحقیق درباره Data Augmentation\n",
    "\n",
    "به زبان ساده می توان گفت هدف از این فرآیند افزایش بهینه و صحیح داده ها برای فاز آموزش مدل های یادگیری ماشین است، هر چند بر روی کاغذ تقریبا پیاده سازی این عملیات بر روی هر نوع داده ای ممکن است، اما بیشتر از همه این فرآیند بر روی حوزه بینایی ماشین پیاده سازی می شود چراکه برای مثال پیاده سازی اون بر روی حوزه *پردازش زبان طبیعی* چالش های بسیار بیشتری به همراه دارد که به ماهیت ساختاری زبان بر میگردد\n",
    "\n",
    "یکی دیگر از حوزه هایی که به شدت این به اصطلاح ساخت دادگان مصنوعی(افزایش دادگان) مورد استفاده قرار می گیرد در حوزه پزشکیست، دلایل متعددی در این حوزه وجود دارد که استفاده از این فرآیند را ضرورت می بخشد، این دلایل عبارتند از\n",
    "* محدود بودن دیتاست ها برای تصاویر پزشکی\n",
    "* محدودیت های قانونی اشتراک گذاری اطلاعات بیماران\n",
    "* تعداد کم بیماران در شاخه های بیماری های نادر و به طبع دیتاست های کوچک و محدود در خصوص این بیماری ها\n",
    "\n",
    "لینک اطلاعات تکمیلی شامل مزایا، چالش های فنی، کتابخانه ها و فریم ورک های مورد استفاده:\n",
    "<br />\n",
    "[data_augmentation](https://research.aimultiple.com/data-augmentation/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## نکته قابل توجه تعدد بسیار زیاد ابزار ها و ماژول های متنوعی بود که برای ما استفاده از این فرآیند رو امکان پذیر می کنند\n",
    "\n",
    "اما قبل از اون دیدن تکنیک های کلی این پروسه برای زمینه های مختلف هم خالی از لطف نیست"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation techniques\n",
    "\n",
    "### We can apply various changes to the initial data. For example, for images we can use:\n",
    "\n",
    "1. Geometric transformations – you can randomly flip, crop, rotate or translate images, and that is just the tip of the iceberg\n",
    "1. Color space transformations – change RGB color channels, intensify any color\n",
    "1. Kernel filters – sharpen or blur an image \n",
    "1. Random Erasing – delete a part of the initial image\n",
    "1. Mixing images – basically, mix images with one another. Might be counterintuitive but it works\n",
    "\n",
    "### For text there are:\n",
    "\n",
    "1. Word/sentence shuffling\n",
    "1. Word replacement – replace words with synonyms\n",
    "1. Syntax-tree manipulation – paraphrase the sentence to be grammatically correct using the same words\n",
    "1. Other described in the article about Data Augmentation in NLP\n",
    "\n",
    "### For audio augmentation you can use:\n",
    "\n",
    "1. Noise injection\n",
    "1. Shifting\n",
    "1. Changing the speed of the tape\n",
    "1. And many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## و اما افزایش داده ها در یادگیری عمیق\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation in Deep Learning\n",
    "As mentioned above in Deep Learning, Data Augmentation is a common practice. Therefore, every DL framework has its own augmentation methods or even a whole library. For example, let’s see how to apply image augmentations using built-in methods in TensorFlow (TF) and Keras, PyTorch, and MxNet.\n",
    "\n",
    "### Data Augmentation in TensorFlow and Keras\n",
    "To augment images when using TensorFlow or Keras as our DL framework we can:\n",
    "\n",
    "1. Write our own augmentation pipelines or layers using tf.image.\n",
    "1. Use Keras preprocessing layers\n",
    "1. Use ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[لینک منبع اصلی جهت مشاهده کد های نمونه](https://neptune.ai/blog/data-augmentation-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Augmentation libraries\n",
    "\n",
    "In this section, we will talk about the following libraries :\n",
    "\n",
    "1. Augmentor\n",
    "1. Albumentations\n",
    "1. Imgaug\n",
    "1. AutoAugment (DeepAugment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "که در نهایت کد مثال اول این فایل رو من با استفاده از اولین لایبرری ذکر شده در اینجا نوشتم،نکته جالب در خصوص این تعدد لایبرری ها تفاوت سرعت عملکرد اونها و فانکشن های در دسترس اونها بود"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bcd4672ee8f888a7bded2ff4d043132575272fe78a45c599617e4885e280f0e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
